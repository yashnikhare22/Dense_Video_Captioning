{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2FuE_r6FNB7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645548234092,"user_tz":-330,"elapsed":25167,"user":{"displayName":"YASH NIKHARE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOPBRZKzmCufVstN4cIswv99A7wtDJdcUp4tP9A=s64","userId":"17573027220439733493"}},"outputId":"cd0c35d9-3b12-49ef-8e97-01682745f14b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5489,"status":"ok","timestamp":1645548239566,"user":{"displayName":"YASH NIKHARE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOPBRZKzmCufVstN4cIswv99A7wtDJdcUp4tP9A=s64","userId":"17573027220439733493"},"user_tz":-330},"id":"OHIqDSIGNCdo","outputId":"19668345-fb1d-40ff-ea18-7a9d03cbe921"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scenedetect[opencv]\n","  Downloading scenedetect-0.5.6.1-py2.py3-none-any.whl (98 kB)\n","\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 20 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from scenedetect[opencv]) (4.62.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scenedetect[opencv]) (1.21.5)\n","Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from scenedetect[opencv]) (7.1.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from scenedetect[opencv]) (4.1.2.30)\n","Installing collected packages: scenedetect\n","Successfully installed scenedetect-0.5.6.1\n","/content/drive/MyDrive/Dense-Video-Captioning/config.py\n","/content/drive/MyDrive/Dense-Video-Captioning/extract_features.py\n","train_path = \"/content/drive/MyDrive/Dense-Video-Captioning/data/training_data\"\n","test_path = \"/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/\"\n","batch_size = 320\n","learning_rate = 0.0007\n","epochs = 150\n","latent_dim =256\n","num_encoder_tokens = 2560\n","num_decoder_tokens = 1500\n","time_steps_encoder = 20\n","max_probability = -1\n","save_model_path = 'model_stacked'\n","validation_split = 0.15\n","max_length = 10\n","search_type = 'beam'\n"]}],"source":["!pip install scenedetect[opencv]\n","!cd /content/drive/MyDrive/Dense-Video-Captioning/\n","\n","!ls /content/drive/MyDrive/Dense-Video-Captioning/*.py\n","\n","!cat /content/drive/MyDrive/Dense-Video-Captioning/config.py\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Dense-Video-Captioning/')\n","import os\n","os.chdir('/content/drive/MyDrive')\n","import config\n","from scenedetect import VideoManager, SceneManager, StatsManager\n","from scenedetect.detectors import ContentDetector\n","from scenedetect.scene_manager import save_images, write_scene_list_html\n","from google.colab.patches import cv2_imshow\n","import math"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51223,"status":"ok","timestamp":1645548298701,"user":{"displayName":"YASH NIKHARE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOPBRZKzmCufVstN4cIswv99A7wtDJdcUp4tP9A=s64","userId":"17573027220439733493"},"user_tz":-330},"id":"f5TfNvT-M9IR","outputId":"905b5a7f-9ace-4c39-abb7-450ae768c8b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/extended_omw.zip.\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw.zip.\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet.zip.\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]}],"source":["import functools\n","import operator\n","import os\n","import time\n","import json\n","import joblib\n","import numpy as np\n","from keras.layers import Input, LSTM, Dense\n","from keras.models import Model, load_model\n","import config\n","import nltk\n","nltk.download('all')\n","from nltk.tokenize import word_tokenize\n","import math\n","import extract_features"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"63mzNBS4M9IT","executionInfo":{"status":"ok","timestamp":1645548299306,"user_tz":-330,"elapsed":642,"user":{"displayName":"YASH NIKHARE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOPBRZKzmCufVstN4cIswv99A7wtDJdcUp4tP9A=s64","userId":"17573027220439733493"}}},"outputs":[],"source":["import config\n","class VideoDescriptionInference(object):\n","    \"\"\"\n","            Initialize the parameters for the model\n","            \"\"\"\n","    def __init__(self, config):\n","        self.latent_dim = config.latent_dim\n","        print(self.latent_dim)\n","        self.num_encoder_tokens = config.num_encoder_tokens\n","        self.num_decoder_tokens = config.num_decoder_tokens\n","        self.time_steps_encoder = config.time_steps_encoder\n","        self.max_probability = config.max_probability\n","\n","        # models\n","        self.encoder_model = None\n","        self.decoder_model = None\n","        self.inf_encoder_model = None\n","        self.inf_decoder_model = None\n","        self.save_model_path = config.save_model_path\n","        self.test_path = config.test_path\n","        self.search_type = config.search_type\n","        self.tokenizer = None\n","\n","    def load_inference_models(self):\n","        # load tokenizer\n","\n","        with open(\"/content/drive/MyDrive/Dense-Video-Captioning/model_stacked/tokenizer1500\", 'rb') as file:\n","            self.tokenizer = joblib.load(file)\n","        print(\"tokenixer\")\n","        # inference encoder model\n","        self.inf_encoder_model = load_model(\"/content/drive/MyDrive/Dense-Video-Captioning/model_stacked/encoder_model.h5\")\n","        print(\"encoder\")\n","        \"\"\"decoder_lstm1 = LSTM(latent_dim*2, return_sequences=True, return_state=True, name='decoder_lstm')\n","        d_outputs, _, _ = decoder_lstm1(decoder_inputs, initial_state=encoder_states)\n","        decoder_lstm2 = LSTM(latent_dim*2, return_sequences=True, return_state=True, name='decoder_lstm2')\n","        final, dh2, dc2 =decoder_lstm2(d_outputs,initial_state=[state_h, state_c])\n","        decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_relu')\n","        decoder_outputs = decoder_dense(final)\n","        \"\"\"\n","        # inference decoder model\n","        decoder_inputs = Input(shape=(None, self.num_decoder_tokens))\n","        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax')\n","        decoder_lstm1 = LSTM(self.latent_dim*2, return_sequences=True, return_state=True)\n","        decoder_state_input_h = Input(shape=(self.latent_dim*2,))\n","        decoder_state_input_c = Input(shape=(self.latent_dim*2,))\n","        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","        decoder_outputs1, state_h1, state_c1 = decoder_lstm1(decoder_inputs, initial_state=decoder_states_inputs)\n","\n","        decoder_lstm2 = LSTM(self.latent_dim*2, return_sequences=True, return_state=True)\n","        decoder_outputs, state_h, state_c =decoder_lstm2(decoder_outputs1,initial_state=[state_h1, state_c1])\n","\n","        decoder_states = [state_h, state_c]\n","        decoder_outputs = decoder_dense(decoder_outputs)\n","        self.inf_decoder_model = Model(\n","            [decoder_inputs] + decoder_states_inputs,\n","            [decoder_outputs] + decoder_states)\n","        self.inf_decoder_model.load_weights(\"/content/drive/MyDrive/Dense-Video-Captioning/model_stacked/decoder_model_weights.h5\")\n","        print(\"decoder\")\n","\n","    def greedy_search(self, f):\n","        \"\"\"\n","\n","                :param f: the loaded numpy array after creating videos to frames and extracting features\n","                :return: the final sentence which has been predicted greedily\n","                \"\"\"\n","        inv_map = self.index_to_word()\n","        states_value = self.inf_encoder_model.predict(f.reshape(-1, 20,2560))\n","        target_seq = np.zeros((1, 1, 1500))\n","        sentence = ''\n","        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n","        for i in range(15):\n","            output_tokens, h, c = self.inf_decoder_model.predict([target_seq] + states_value)\n","            states_value = [h, c]\n","            output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n","            y_hat = np.argmax(output_tokens)\n","            if y_hat == 0:\n","                continue\n","            if inv_map[y_hat] is None:\n","                break\n","            else:\n","                sentence = sentence + inv_map[y_hat] + ' '\n","                target_seq = np.zeros((1, 1, 1500))\n","                target_seq[0, 0, y_hat] = 1\n","        return ' '.join(sentence.split()[:-1])\n","\n","    def decode_sequence2bs(self, input_seq):\n","        states_value = self.inf_encoder_model.predict(input_seq)\n","        target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n","        target_seq[0, 0, self.tokenizer.word_index['bos']] = 1\n","        self.beam_search(target_seq, states_value, [], [], 0)\n","        return decode_seq\n","\n","    def beam_search(self, target_seq, states_value, prob, path, lens):\n","        \"\"\"\n","\n","                :param target_seq: the array that is fed into the model to predict the next word\n","                :param states_value: previous state that is fed into the lstm cell\n","                :param prob: probability of predicting a word\n","                :param path: list of words from each sentence\n","                :param lens: number of words\n","                :return: final sentence\n","                \"\"\"\n","        global decode_seq\n","        node = 2\n","        output_tokens, h, c = self.inf_decoder_model.predict(\n","            [target_seq] + states_value)\n","        output_tokens = output_tokens.reshape(self.num_decoder_tokens)\n","        sampled_token_index = output_tokens.argsort()[-node:][::-1]\n","        states_value = [h, c]\n","        for i in range(node):\n","            if sampled_token_index[i] == 0:\n","                sampled_char = ''\n","            else:\n","                sampled_char = list(self.tokenizer.word_index.keys())[\n","                    list(self.tokenizer.word_index.values()).index(sampled_token_index[i])]\n","            MAX_LEN = 12\n","            if sampled_char != 'eos' and lens <= MAX_LEN:\n","                p = output_tokens[sampled_token_index[i]]\n","                if sampled_char == '':\n","                    p = 1\n","                prob_new = list(prob)\n","                prob_new.append(p)\n","                path_new = list(path)\n","                path_new.append(sampled_char)\n","                target_seq = np.zeros((1, 1, self.num_decoder_tokens))\n","                target_seq[0, 0, sampled_token_index[i]] = 1.\n","                self.beam_search(target_seq, states_value, prob_new, path_new, lens + 1)\n","            else:\n","                p = output_tokens[sampled_token_index[i]]\n","                prob_new = list(prob)\n","                prob_new.append(p)\n","                p = functools.reduce(operator.mul, prob_new, 1)\n","                if p > self.max_probability:\n","                    decode_seq = path\n","                    self.max_probability = p\n","\n","    def decoded_sentence_tuning(self, decoded_sentence):\n","        decode_str = []\n","        filter_string = ['bos', 'eos']\n","        uni_gram = {}\n","        last_string = \"\"\n","        for idx2, c in enumerate(decoded_sentence):\n","            if c in uni_gram:\n","                uni_gram[c] += 1\n","            else:\n","                uni_gram[c] = 1\n","            if last_string == c and idx2 > 0:\n","                continue\n","            if c in filter_string:\n","                continue\n","            if len(c) > 0:\n","                decode_str.append(c)\n","            if idx2 > 0:\n","                last_string = c\n","        return decode_str\n","\n","    def index_to_word(self):\n","        # inverts word tokenizer\n","        index_to_word = {value: key for key, value in self.tokenizer.word_index.items()}\n","        return index_to_word\n","\n","    def get_test_data(self):\n","        \"\"\"\n","        loads all the numpy files\n","        :return: two lists containing all the video arrays and the video Id\n","        \"\"\"\n","        X_test = []\n","        X_test_filename = []\n","        file_list = os.listdir(os.path.join(self.test_path, 'video'))\n","        for index in range(len(file_list)):\n","            filename= file_list[index]\n","            scenes = extract_features.proposal_module(filename)\n","            scenes= math.floor(len(scenes)/2)\n","            featList=[]\n","            for i in range(0, scenes):\n","              if i==0:\n","                path = os.path.join(self.test_path, 'feat_test', filename.split(\".\")[0] + '.npy')\n","                print(path)\n","              else:\n","                path = os.path.join(self.test_path, 'feat_test', filename.split(\".\")[0] + \"_\"+  str(i+1)+ '.npy')\n","              \n","              if os.path.exists(path):\n","                  f = np.load(path)\n","                  featList.append(f)\n","            #print(featList)\n","            #print(\"size of featList \" +  str(len(featList)))\n","            X_test.append(featList)\n","            #print(\"size of xtest \" +  str(len(X_test)))\n","            X_test_filename.append(filename[:-4])            \n","        #X_test = np.array(X_test)   \n","        #print( \"length of xtest is \" + str(len(X_test)) )\n","        #print(X_test)\n","        return X_test, X_test_filename\n","\n","    def test(self):\n","        \"\"\"\n","            writes the captions of all the testing videos in a text file\n","        \"\"\"\n","        X_test, X_test_filename = self.get_test_data()\n","        #print(X_test_filename)\n","        #print(X_test)\n","        # generate inference test outputs\n","        with open(\"/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/Beam2_Stacked.txt\", 'w') as file:\n","            #file.write(X_test_filename)\n","            file.write(X_test_filename[0] + ',')\n","            for idx in range(0,len(X_test)):\n","                print(idx)\n","                file.write(X_test_filename[idx] + ',')\n","                listOfSentences=[]\n","                for j in range(0,len(X_test[idx])):\n","                  if self.search_type == 'greedy':\n","                          feature = np.array(X_test[idx][j])\n","                          sentence_predicted = self.greedy_search(feature.reshape((-1, 20, 2560)))\n","                          listOfSentences.append(str(sentence_predicted))\n","                          file.write(str(listOfSentences)+ \"\\n\")\n","                  else:\n","                          sentence_predicted = ''\n","                          feature = np.array(X_test[idx][j])\n","                          decoded_sentence = self.decode_sequence2bs(feature.reshape((-1, 20, 2560)))\n","                          decode_str = self.decoded_sentence_tuning(decoded_sentence)\n","                          for d in decode_str:\n","                              sentence_predicted = sentence_predicted + d + ' '\n","                              listOfSentences.append(str(sentence_predicted))\n","                              file.write(str(listOfSentences))\n","\n","                      #file.write(str(listOfSentences))\n","                # re-init max prob\n","                self.max_probability = -1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AccCPuETM9IZ","outputId":"e441f3ff-5c5e-4f87-b8e4-c476f1db5614"},"outputs":[{"output_type":"stream","name":"stdout","text":["256\n","tokenixer\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","encoder\n","decoder\n","Processing video for detecting scenes 778mkceE0UQ_40_46.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 360/360 [00:01<00:00, 336.51frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/778mkceE0UQ_40_46.npy\n","Processing video for detecting scenes lw7pTwpx0K0_38_48.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 300/300 [00:03<00:00, 80.73frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/lw7pTwpx0K0_38_48.npy\n","Processing video for detecting scenes sZf3VDsdDPM_107_114.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:00<00:00, 494.31frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/sZf3VDsdDPM_107_114.npy\n","Processing video for detecting scenes RZL9irxnhZ0_34_40.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180/180 [00:00<00:00, 437.86frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/RZL9irxnhZ0_34_40.npy\n","Processing video for detecting scenes 6q1dX6thX3E_286_295.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 226/226 [00:00<00:00, 497.67frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/6q1dX6thX3E_286_295.npy\n","Processing video for detecting scenes Dgf0VHMEtNs_57_66.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 270/270 [00:00<00:00, 604.30frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/Dgf0VHMEtNs_57_66.npy\n","Processing video for detecting scenes IhwPQL9dFYc_124_129.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:00<00:00, 507.27frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/IhwPQL9dFYc_124_129.npy\n","Processing video for detecting scenes xCFCXzDUGjY_5_9.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:00<00:00, 479.69frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["5 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/xCFCXzDUGjY_5_9.npy\n","Processing video for detecting scenes ufFT2BWh3BQ_0_8.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [00:00<00:00, 346.79frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/ufFT2BWh3BQ_0_8.npy\n","Processing video for detecting scenes 3qqEKTPxLNs_1_15.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 421/421 [00:01<00:00, 406.70frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/3qqEKTPxLNs_1_15.npy\n","Processing video for detecting scenes UbmZAe5u5FI_132_141.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 270/270 [00:00<00:00, 450.11frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/UbmZAe5u5FI_132_141.npy\n","Processing video for detecting scenes e-j59PqJjSM_50_98.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1441/1441 [00:04<00:00, 359.28frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/e-j59PqJjSM_50_98.npy\n","Processing video for detecting scenes PeUHy0A1GF0_114_121.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 210/210 [00:00<00:00, 305.25frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/PeUHy0A1GF0_114_121.npy\n","Processing video for detecting scenes BAf3LXFUaGs_28_38.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 251/251 [00:00<00:00, 259.58frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/BAf3LXFUaGs_28_38.npy\n","Processing video for detecting scenes 77iDIp40m9E_126_131.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [00:00<00:00, 373.31frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/77iDIp40m9E_126_131.npy\n","Processing video for detecting scenes 04Gt01vatkk_248_265.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 511/511 [00:01<00:00, 444.19frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/04Gt01vatkk_248_265.npy\n","Processing video for detecting scenes 7NNg0_n-bS8_21_30.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 270/270 [00:00<00:00, 369.20frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/7NNg0_n-bS8_21_30.npy\n","Processing video for detecting scenes He7Ge7Sogrk_47_70.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 576/576 [00:01<00:00, 497.58frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/He7Ge7Sogrk_47_70.npy\n","Processing video for detecting scenes k5OKBX2e7xA_19_32.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:00<00:00, 524.95frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["9 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/k5OKBX2e7xA_19_32.npy\n","Processing video for detecting scenes XOAgUVVwKEA_8_20.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 289/289 [00:00<00:00, 363.53frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/XOAgUVVwKEA_8_20.npy\n","Processing video for detecting scenes WWf0Z6ak3Dg_5_15.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 300/300 [00:00<00:00, 469.00frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/WWf0Z6ak3Dg_5_15.npy\n","Processing video for detecting scenes HAjwXjwN9-A_16_24.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [00:00<00:00, 470.12frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/HAjwXjwN9-A_16_24.npy\n","Processing video for detecting scenes Jag7oTemldY_12_25.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 326/326 [00:00<00:00, 416.93frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/Jag7oTemldY_12_25.npy\n","Processing video for detecting scenes 5YJaS2Eswg0_22_26.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 113/113 [00:00<00:00, 392.17frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/5YJaS2Eswg0_22_26.npy\n","Processing video for detecting scenes jTnrm338_KY_34_42.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [00:00<00:00, 392.44frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/jTnrm338_KY_34_42.npy\n","Processing video for detecting scenes BtQtRGI0F2Q_15_20.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 151/151 [00:00<00:00, 449.42frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/BtQtRGI0F2Q_15_20.npy\n","Processing video for detecting scenes 4PcL6-mjRNk_11_18.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 211/211 [00:00<00:00, 401.47frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/4PcL6-mjRNk_11_18.npy\n","Processing video for detecting scenes 6JnGBs88sL0_4_10.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 144/144 [00:00<00:00, 242.72frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/6JnGBs88sL0_4_10.npy\n","Processing video for detecting scenes dfOuTx66bJU_34_39.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 151/151 [00:00<00:00, 394.25frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/dfOuTx66bJU_34_39.npy\n","Processing video for detecting scenes glrijRGnmc0_211_215.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:00<00:00, 370.30frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/glrijRGnmc0_211_215.npy\n","Processing video for detecting scenes bqMmyY1ImkI_0_14.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 211/211 [00:00<00:00, 479.44frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/bqMmyY1ImkI_0_14.npy\n","Processing video for detecting scenes shPymuahrsc_5_12.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169/169 [00:01<00:00, 150.52frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/shPymuahrsc_5_12.npy\n","Processing video for detecting scenes wkgGxsuNVSg_34_41.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 176/176 [00:00<00:00, 519.85frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/wkgGxsuNVSg_34_41.npy\n","Processing video for detecting scenes q7pOFn8s4zc_263_273.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 301/301 [00:00<00:00, 509.13frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/q7pOFn8s4zc_263_273.npy\n","Processing video for detecting scenes ScdUht-pM6s_53_63.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 600/600 [00:01<00:00, 510.59frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/ScdUht-pM6s_53_63.npy\n","Processing video for detecting scenes mtrCf667KDk_134_176.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1259/1259 [00:03<00:00, 365.39frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/mtrCf667KDk_134_176.npy\n","Processing video for detecting scenes 4xVGpDmA4lE_23_33.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 301/301 [00:00<00:00, 507.02frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["5 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/4xVGpDmA4lE_23_33.npy\n","Processing video for detecting scenes JntMAcTlOF0_50_70.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 501/501 [00:01<00:00, 413.83frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["5 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/JntMAcTlOF0_50_70.npy\n","Processing video for detecting scenes e-j59PqJjSM_405_416.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 331/331 [00:00<00:00, 498.53frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/e-j59PqJjSM_405_416.npy\n","Processing video for detecting scenes 0lh_UWF9ZP4_62_69.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 210/210 [00:00<00:00, 491.58frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/0lh_UWF9ZP4_62_69.npy\n","Processing video for detecting scenes tJHUH9tpqPg_113_118.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:00<00:00, 172.19frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/tJHUH9tpqPg_113_118.npy\n","Processing video for detecting scenes rl1rVk_xIOs_1_16.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 450/450 [00:00<00:00, 471.66frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/rl1rVk_xIOs_1_16.npy\n","Processing video for detecting scenes EpMuCrbxE8A_107_115.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 241/241 [00:00<00:00, 419.64frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["12 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/EpMuCrbxE8A_107_115.npy\n","Processing video for detecting scenes 8MVo7fje_oE_125_130.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:00<00:00, 493.92frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/8MVo7fje_oE_125_130.npy\n","Processing video for detecting scenes RjpbFlOHFps_8_25.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 426/426 [00:00<00:00, 437.87frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/RjpbFlOHFps_8_25.npy\n","Processing video for detecting scenes n016q1w8Q30_2_11.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 270/270 [00:00<00:00, 325.99frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/n016q1w8Q30_2_11.npy\n","Processing video for detecting scenes UdcObAQ5OOM_15_30.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 360/360 [00:01<00:00, 327.47frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["4 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/UdcObAQ5OOM_15_30.npy\n","Processing video for detecting scenes f9Won2JpOEU_60_80.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 600/600 [00:01<00:00, 349.41frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/f9Won2JpOEU_60_80.npy\n","Processing video for detecting scenes klteYv1Uv9A_27_33.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 91/91 [00:00<00:00, 355.79frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["5 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/klteYv1Uv9A_27_33.npy\n","Processing video for detecting scenes k06Ge9ANKM8_5_16.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 166/166 [00:00<00:00, 490.91frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/k06Ge9ANKM8_5_16.npy\n","Processing video for detecting scenes 04Gt01vatkk_308_321.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:00<00:00, 429.13frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/04Gt01vatkk_308_321.npy\n","Processing video for detecting scenes 71soiLO6I9U_15_24.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 135/135 [00:00<00:00, 458.32frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/71soiLO6I9U_15_24.npy\n","Processing video for detecting scenes 1Sp2__RCT0c_11_15.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:00<00:00, 492.62frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/1Sp2__RCT0c_11_15.npy\n","Processing video for detecting scenes 30GeJHYoerk_121_126.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [00:00<00:00, 429.35frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/30GeJHYoerk_121_126.npy\n","Processing video for detecting scenes 7HcYJKMxpcg_20_28.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [00:01<00:00, 168.98frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/7HcYJKMxpcg_20_28.npy\n","Processing video for detecting scenes 0lh_UWF9ZP4_27_31.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:00<00:00, 467.40frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/0lh_UWF9ZP4_27_31.npy\n","Processing video for detecting scenes 88DOMJ11q2M_84_87.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 90/90 [00:00<00:00, 351.61frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/88DOMJ11q2M_84_87.npy\n","Processing video for detecting scenes 8HB7ywgJuTg_131_142.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 331/331 [00:00<00:00, 519.13frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/8HB7ywgJuTg_131_142.npy\n","Processing video for detecting scenes 5HAf_INrFy0_3_25.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 331/331 [00:00<00:00, 511.38frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/5HAf_INrFy0_3_25.npy\n","Processing video for detecting scenes aM-RcQj0a7I_37_55.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 451/451 [00:01<00:00, 324.29frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/aM-RcQj0a7I_37_55.npy\n","Processing video for detecting scenes J---aiyznGQ_0_6.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 90/90 [00:00<00:00, 491.01frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/J---aiyznGQ_0_6.npy\n","Processing video for detecting scenes J_evFB7RIKA_104_120.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [00:03<00:00, 67.54frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/J_evFB7RIKA_104_120.npy\n","Processing video for detecting scenes mmSQTI6gMNQ_120_128.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 240/240 [00:00<00:00, 536.52frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/mmSQTI6gMNQ_120_128.npy\n","Processing video for detecting scenes Fe4tO5vW9_E_64_70.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 151/151 [00:00<00:00, 410.44frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/Fe4tO5vW9_E_64_70.npy\n","Processing video for detecting scenes ecm9gf2Pgkc_1_24.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 690/690 [00:01<00:00, 487.39frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["4 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/ecm9gf2Pgkc_1_24.npy\n","Processing video for detecting scenes CGllPWAwmUo_1_15.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 419/419 [00:00<00:00, 552.24frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["6 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/CGllPWAwmUo_1_15.npy\n","Processing video for detecting scenes cnsjm3fNEec_4_10.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180/180 [00:00<00:00, 515.90frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["6 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/cnsjm3fNEec_4_10.npy\n","Processing video for detecting scenes jbzaMtPYtl8_48_58.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 300/300 [00:00<00:00, 382.03frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/jbzaMtPYtl8_48_58.npy\n","Processing video for detecting scenes g1Gldu1KS44_8_14.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180/180 [00:00<00:00, 374.84frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/g1Gldu1KS44_8_14.npy\n","Processing video for detecting scenes HV12kTtdTT4_5_14.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 271/271 [00:00<00:00, 486.15frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/HV12kTtdTT4_5_14.npy\n","Processing video for detecting scenes Cjf21Y19aUQ_82_86.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [00:00<00:00, 498.00frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/Cjf21Y19aUQ_82_86.npy\n","Processing video for detecting scenes DhwrBs96Kgk_120_124.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:00<00:00, 384.15frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/DhwrBs96Kgk_120_124.npy\n","Processing video for detecting scenes j2Dhf-xFUxU_13_20.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 106/106 [00:00<00:00, 515.55frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/j2Dhf-xFUxU_13_20.npy\n","Processing video for detecting scenes Je3V7U5Ctj4_569_576.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 210/210 [00:01<00:00, 163.11frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/Je3V7U5Ctj4_569_576.npy\n","Processing video for detecting scenes inzk2fTUe1w_1_15.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 211/211 [00:00<00:00, 489.16frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/inzk2fTUe1w_1_15.npy\n","Processing video for detecting scenes lo4KcsBN--A_0_10.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 300/300 [00:00<00:00, 313.72frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/lo4KcsBN--A_0_10.npy\n","Processing video for detecting scenes qvg9eM4Hmzk_4_10.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 91/91 [00:00<00:00, 353.34frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/qvg9eM4Hmzk_4_10.npy\n","Processing video for detecting scenes uJPupV4oLZ0_4_12.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 201/201 [00:00<00:00, 426.48frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/uJPupV4oLZ0_4_12.npy\n","Processing video for detecting scenes N2Cm0SLr0ZE_18_29.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 322/322 [00:00<00:00, 557.61frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/N2Cm0SLr0ZE_18_29.npy\n","Processing video for detecting scenes YmXCfQm0_CA_277_284.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 420/420 [00:01<00:00, 344.53frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["6 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/YmXCfQm0_CA_277_284.npy\n","Processing video for detecting scenes RSx5G0_xH48_12_17.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 151/151 [00:00<00:00, 348.31frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/RSx5G0_xH48_12_17.npy\n","Processing video for detecting scenes WTf5EgVY5uU_124_128.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 120/120 [00:00<00:00, 519.47frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/WTf5EgVY5uU_124_128.npy\n","Processing video for detecting scenes zv2RIbUsnSw_335_341.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180/180 [00:01<00:00, 148.85frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/zv2RIbUsnSw_335_341.npy\n","Processing video for detecting scenes xxHx6s_DbUo_216_222.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 144/144 [00:00<00:00, 495.48frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["4 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/xxHx6s_DbUo_216_222.npy\n","Processing video for detecting scenes zulPFoY64wE_26_33.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 168/168 [00:00<00:00, 376.03frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/zulPFoY64wE_26_33.npy\n","Processing video for detecting scenes qeKX-N1nKiM_0_5.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:00<00:00, 493.25frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/qeKX-N1nKiM_0_5.npy\n","Processing video for detecting scenes MrQd1zUVRUM_103_110.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 210/210 [00:00<00:00, 359.81frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/MrQd1zUVRUM_103_110.npy\n","Processing video for detecting scenes UXs3eq68ZjE_250_255.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 150/150 [00:00<00:00, 178.98frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/UXs3eq68ZjE_250_255.npy\n","Processing video for detecting scenes tcxhOGyrCtI_15_21.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 151/151 [00:00<00:00, 390.71frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/tcxhOGyrCtI_15_21.npy\n","Processing video for detecting scenes qLwgb3F0aPU_298_305.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 168/168 [00:00<00:00, 471.40frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["3 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/qLwgb3F0aPU_298_305.npy\n","Processing video for detecting scenes ZbtpcGi2DWY_161_170.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 270/270 [00:00<00:00, 536.75frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/ZbtpcGi2DWY_161_170.npy\n","Processing video for detecting scenes sJSmRik2c-c_1_7.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 180/180 [00:00<00:00, 438.56frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/sJSmRik2c-c_1_7.npy\n","Processing video for detecting scenes u4T76jsPin0_0_11.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 265/265 [00:00<00:00, 492.02frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/u4T76jsPin0_0_11.npy\n","Processing video for detecting scenes N3A7944_UJw_63_70.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 211/211 [00:00<00:00, 338.76frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["2 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/N3A7944_UJw_63_70.npy\n","Processing video for detecting scenes MTjrZthHwJQ_2_11.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 136/136 [00:00<00:00, 1539.97frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/MTjrZthHwJQ_2_11.npy\n","Processing video for detecting scenes TZ860P4iTaM_15_28.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 195/195 [00:00<00:00, 509.95frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/TZ860P4iTaM_15_28.npy\n","Processing video for detecting scenes v7iIZXtpIb8_5_15.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [00:01<00:00, 161.55frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/v7iIZXtpIb8_5_15.npy\n","Processing video for detecting scenes s1ZABV7AQdA_38_48.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 301/301 [00:00<00:00, 493.23frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/s1ZABV7AQdA_38_48.npy\n","Processing video for detecting scenes pW9DFPqoIsI_26_50.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 601/601 [00:01<00:00, 357.83frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["7 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/pW9DFPqoIsI_26_50.npy\n","Processing video for detecting scenes NUYu9c9XsgY_7_21.avi\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 211/211 [00:00<00:00, 499.09frames/s]\n"]},{"output_type":"stream","name":"stdout","text":["1 scenes detected!\n","/content/drive/MyDrive/Dense-Video-Captioning/data/testing_data/feat_test/NUYu9c9XsgY_7_21.npy\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n"]}],"source":["\n","if __name__ == \"__main__\":\n","    video_to_text = VideoDescriptionInference(config)\n","    video_to_text.load_inference_models()\n","    video_to_text.test()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":2903,"status":"error","timestamp":1642242821188,"user":{"displayName":"SWARALI PURANDARE","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01266572673575207395"},"user_tz":-330},"id":"z4HYyRWYe9NH","outputId":"699a3852-ae31-4c6e-8d8b-a400af3d5d4d"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-21bb92306c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Video-Captioning-main/data/testing_data/test_greedy.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtest_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Video-Captioning-main/data/testing_data/test_greedy.txt'"]}],"source":["test_result={}\n","with open(\"/content/drive/MyDrive/Video-Captioning-main/data/testing_data/test_greedy.txt\",\"r\") as test_file:    \n","    for line in test_file.readlines():\n","      y_data = line.split(\",\")\n","      test_result[y_data[0]] = str(y_data[1])\n","\n","print(test_result)\n","#nltk.translate.bleu_score.sentence_bleu(references, hypothesis)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1TEbFLNlobB"},"outputs":[],"source":["test_label={}\n","count=0\n","with open(\"/content/drive/MyDrive/Video-Captioning-main/data/testing_data/testing_label.txt\",\"r\") as test_file:    \n","    for line in test_file.readlines():\n","      count+=1\n","      y_dataID = line.split(\" \")[0]\n","      y_dataVal = line.partition(' ')[2]\n","      #print(str(y_dataID) + str(y_dataVal))\n","      if str(y_dataID) in test_result:\n","        if str(y_dataID) in test_label:\n","          test_label[y_dataID]=(str(y_dataVal))\n","          #print(test_label[y_dataID])\n","        else:\n","          if count==1:\n","            count+=1\n","            continue\n","          else:\n","            test_label[y_dataID] = (str(y_dataVal))\n","          #print(test_label[y_dataID])\n","      \n","      else:\n","        continue\n","\n","print(test_label)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R86xoBcKHi3B"},"outputs":[],"source":["print((y_dataVal).split(\" \"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuL3KX8Qt2z0"},"outputs":[],"source":["print(test_label)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqMJKeBit7QH"},"outputs":[],"source":["\n","with open(\"/content/drive/MyDrive/Video-Captioning-main/data/testing_data/Finaltesting_label2.txt\",\"w\") as test_file:\n","  for key, value in test_label.items(): \n","    test_file.write('%s:%s\\n' % (key, value))   \n","   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGsZXtayx-SR"},"outputs":[],"source":["\n","with open(\"/content/drive/MyDrive/Video-Captioning-main/data/testing_data/FinalTestGreedy.txt\",\"w\") as test_file:\n","  for i in sorted (test_result) :\n","    test_file.write('%s:%s\\n' % (i, test_result[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vv4FT4JR_tc"},"outputs":[],"source":["index=0\n","BLEUlist=[]\n","for key1,val1 in test_label.items():\n","  ref= val1\n","  hypo = test_result[key1]\n","  index+=1\n","  BLEUlist.append(nltk.translate.bleu_score.sentence_bleu(ref, hypo,weights = [0,1,0,0]))\n","  print(str(index) +\" \" + str(key1) +\"  \"+ str(nltk.translate.bleu_score.sentence_bleu(ref, hypo, weights = [0,1,.25,0])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k499WvzaT5CU"},"outputs":[],"source":["print(max(BLEUlist))\n","print(min(BLEUlist))\n","print(sum(BLEUlist)/len(BLEUlist))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-Bgn1_0XWr9"},"outputs":[],"source":["#!pip install -U nltk\n","from nltk.translate.meteor_score import meteor_score\n","index=0\n","METEORlist=[]\n","\n","for key1,val1 in test_label.items():\n","  hypo=[]\n","  hypo .append(test_result[key1])\n","  ref=[]\n","  ref.append(l[0])\n","  print\n","  METEORlist.append(meteor_score(['a woman cuts an oion'], ['a woman is mixing something']))\n","  print(str(index) +\" \" + str(key1) +\"  \"+ str(meteor_score(['a woman cuts an oion'], ['a woman is mixing something'],2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8yJ0iCC_2L4"},"outputs":[],"source":["print (nltk.translate.meteor_score.meteor_score(\n","    [[\"a woman cuts an oion\"]], [\"a woman is mixing something\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kVMUlbep4Ubl"},"outputs":[],"source":["mylist = [['a', 'woman', 'cuts', 'an', 'oion'], ['a', 'girl', 'is', 'cutting', 'an', 'onion'], ['a', 'girl', 'is', 'cutting', 'an', 'onion'], ['a', 'girl', 'is', 'cutting', 'onion', 'into', 'small', 'pieces'], ['a', 'girl', 'is', 'dicing', 'up', 'an', 'onion'], ['a', 'woman', 'chops', 'a', 'white', 'onion'], ['a', 'woman', 'cuts', 'and', 'dices', 'an', 'onion'], ['a', 'woman', 'is', 'chopping', 'an', 'onion', 'into', 'small', 'pieces'], ['a', 'woman', 'is', 'chopping', 'an', 'onion', 'slice', 'into', 'fine', 'pieces'], ['a', 'woman', 'is', 'cutting', 'onions'], ['a', 'woman', 'is', 'slicing', 'a', 'onion'], ['a', 'woman', 'is', 'slicing', 'some', 'vegetables'], ['a', 'woman', 'slices', 'an', 'onion'], ['an', 'onion', 'is', 'chopped', 'up'], ['the', 'cook', 'is', 'dicing', 'onions'], ['the', 'girl', 'is', 'slicing', 'an', 'onion'], ['a', 'woman', 'is', 'cutting', 'the', 'tomato', 'into', 'pieces'], ['a', 'woman', 'is', 'slicing', 'an', 'onion'], ['a', 'young', 'woman', 'cutting', 'an', 'onion', 'to', 'make', 'salsa'], ['a', 'girl', 'is', 'chopping', 'onions'], ['a', 'girl', 'is', 'slicing', 'an', 'onion'], ['a', 'lady', 'is', 'chopping', 'onions'], ['a', 'woman', 'cuts', 'an', 'onion'], ['a', 'woman', 'cutting', 'an', 'onion'], ['a', 'woman', 'in', 'a', 'red', 'dress', 'chopping', 'tomatoes'], ['a', 'woman', 'is', 'chopping', 'onions'], ['a', 'woman', 'is', 'chopping', 'onions'], ['a', 'woman', 'is', 'chopping', 'up', 'onions'], ['a', 'woman', 'is', 'cutting', 'an', 'onion'], ['a', 'woman', 'is', 'cutting', 'onions'], ['a', 'woman', 'is', 'dicing', 'an', 'onion'], ['a', 'woman', 'is', 'dicing', 'an', 'onion'], ['a', 'woman', 'is', 'slicing', 'a', 'salsa'], ['a', 'woman', 'is', 'slicing', 'an', 'onion'], ['a', 'woman', 'is', 'slicing', 'an', 'onion'], ['a', 'woman', 'is', 'slicing', 'and', 'chopping', 'up', 'an', 'onion'], ['a', 'woman', 'is', 'slicing', 'and', 'dicing', 'an', 'onion'], ['a', 'woman', 'is', 'slicing', 'some', 'tomatoes'], ['a', 'woman', 'is', 'slicing', 'some', 'vegetables'], ['a', 'woman', 'is', 'slicing', 'some', 'vegitable'], ['a', 'woman', 'is', 'slicing', 'then', 'dicing', 'an', 'onion'], ['a', 'woman', 'is', 'slicing', 'vegetables'], ['the', 'girl', 'sliced', 'an', 'onion'], ['the', 'girl', 'sliced', 'an', 'onion'], ['the', 'lady', 'is', 'slicing', 'onions'], ['the', 'woman', 'is', 'dicing', 'an', 'onion'], ['woman', 'teaches', 'on', 'how', 'to', 'cook', 'salsa'], ['a', 'lady', 'is', 'cutting', 'onion', 'with', 'the', 'knife']]\n","l=[]\n","for i in mylist:\n","  s=[]\n","  s.append(\" \".join(i))\n","  l.append(s)\n","print(l)"]},{"cell_type":"markdown","metadata":{"id":"WmuBrt9V4_K3"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pCdxTBSXnz1"},"outputs":[],"source":["print(max(METEORlist))\n","print(min(METEORlist))\n","print(sum(METEORlist)/len(METEORlist))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"predict_test.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}